#  برنولی بیز ساده (Bernoulli Naive Bayes)

این کد یک طبقه‌بند برنولی بیز ساده برای تشخیص هرزنامه پیاده‌سازی می‌کند. الگوریتم برای داده‌های باینری (۰ و ۱) طراحی شده است که نشان‌دهنده حضور یا عدم حضور ویژگی‌ها (مانند کلمات) در هر سند هستند. این مدل بر اساس توزیع برنولی عمل می‌کند که هر ویژگی را به عنوان یک آزمایش برنولی مستقل در نظر می‌گیرد.

## بخش ۱: آماده‌سازی اولیه

```
import math

def fmt(x):
    """Format numbers for better display"""
    return f"{x:.4f}"
```
الگوریتم:

نیاز به محاسبات ریاضی پایه

نمایش فرمت‌شده اعداد برای خروجی خوانا

پیاده‌سازی:

کتابخانه math برای محاسبات عمومی

تابع fmt() برای نمایش ۴ رقم اعشار

## بخش ۲: داده‌های آموزشی

```
spam = [[1, 1], [1, 0], [1, 1]]
ham  = [[0, 0], [0, 1], [0, 0]]
x = [1, 0]  # Test email: free=1, win=0
```
الگوریتم:

داده‌های آموزشی به صورت بردارهای باینری

هر سند با دو ویژگی نمایش داده می‌شود: حضور کلمه "free" و "win"

۱ = کلمه وجود دارد، ۰ = کلمه وجود ندارد

یک ایمیل تست برای طبقه‌بندی

پیاده‌سازی:

spam: ۳ ایمیل اسپم

ham: ۳ ایمیل غیراسپم

تست x: ایمیل تست که کلمه "free" دارد ولی "win" ندارد.

## بخش ۳: محاسبه احتمالات ویژگی‌ها با هموارسازی لاپلاس

```
def feature_probability(data, index, feature_name, class_name):
    count = sum(row[index] for row in data)
    n = len(data)
    probability = (count + 1) / (n + 2)
    return probability
```
الگوریتم:

محاسبه P(feature=1|class) با هموارسازی لاپلاس

فرمول: (count(feature=1) + 1) / (n + 2)

هموارسازی لاپلاس از احتمال صفر جلوگیری می‌کند

مقدار ۲ در مخرج = تعداد مقادیر ممکن (۰ و ۱)

پیاده‌سازی:

بخش count: تعداد سندهایی که ویژگی =۱ دارند

متغیر n: تعداد کل سندها در کلاس

محاسبه احتمال با فرمول هموارسازی

## بخش ۴: محاسبه احتمالات شرطی

```
# For spam class:
if x[0] == 1:
    prob_free_spam = p_free_spam
else:
    prob_free_spam = 1 - p_free_spam

p_x_spam = prob_free_spam * prob_win_spam
```
الگوریتم:

اگر ویژگی=۱ باشد: P(feature=1|class)

اگر ویژگی=۰ باشد: 1 - P(feature=1|class)

با فرض استقلال: P(x|class) = Π P(feature_i|class)

حاصل‌ضرب احتمالات تک‌تک ویژگی‌ها

پیاده‌سازی:

بررسی مقدار هر ویژگی در سند تست

انتخاب احتمال مناسب بر اساس مقدار

ضرب احتمالات برای بدست آوردن درست‌نمایی کل

## بخش ۵: احتمالات پیشین (Prior) 
```
p_spam = 0.5
p_ham = 0.5
```
الگوریتم:

فرض تعادل در داده‌های آموزشی:

P(spam) = P(ham) = 0.5

اگر داده متعادل نباشد، می‌توان بر اساس فراوانی محاسبه کرد.

پیاده‌سازی:

مقدار ثابت ۰.۵ برای هر دو کلاس

در داده واقعی: P(class) = تعداد_اسناد_کلاس / کل_اسناد

## بخش ۶: محاسبه احتمالات پسین
```
posterior_spam = p_x_spam * p_spam
posterior_ham = p_x_ham * p_ham
total = posterior_spam + posterior_ham

normalized_spam = posterior_spam / total
normalized_ham = posterior_ham / total
```
لگوریتم:

قاعده بیز: P(class|x) ∝ P(x|class) × P(class)

مقدار غیرنرمال‌شده: حاصل‌ضرب درست‌نمایی و پیشین

نرمال‌سازی: تقسیم هر کدام بر مجموع

P(class|x) = [P(x|class) × P(class)] / Σ[P(x|all_classes) × P(all_classes)]

پیاده‌سازی:

محاسبه مقادیر متناسب

جمع مقادیر برای بدست آوردن ثابت نرمال‌سازی

تقسیم هر مقدار بر مجموع

## بخش ۷: تصمیم‌گیری و محاسبه اطمینان
```
if posterior_spam > posterior_ham:
    decision = "Spam"
    confidence = abs(posterior_spam - posterior_ham) / max(posterior_spam, posterior_ham)
```
الگوریتم:

انتخاب کلاس با بیشترین احتمال پسین

محاسبه میزان اطمینان بر اساس تفاوت نسبی

فرمول اطمینان: |P1 - P2| / max(P1, P2)

اطمینان بین ۰ (تصمیم نامطمئن) تا ۱ (تصمیم کاملاً مطمئن)

پیاده‌سازی:

مقایسه احتمالات نرمال‌شده

تعیین کلاس برنده

محاسبه تفاوت نسبی برای اطمینان

# محاسبات گام به گام برای کد

محاسبه احتمالات ویژگی‌ها:
برای کلاس Spam:

P(free=1|spam) = (3 + 1) / (3 + 2) = 4/5 = 0.8

P(win=1|spam) = (2 + 1) / (3 + 2) = 3/5 = 0.6

برای کلاس Ham:

P(free=1|ham) = (0 + 1) / (3 + 2) = 1/5 = 0.2

P(win=1|ham) = (1 + 1) / (3 + 2) = 2/5 = 0.4

محاسبه درست‌نمایی برای سند تست [1, 0]:
برای Spam:

P(free=1|spam) = 0.8

P(win=0|spam) = 1 - 0.6 = 0.4

P(x|spam) = 0.8 × 0.4 = 0.32

برای Ham:

P(free=1|ham) = 0.2

P(win=0|ham) = 1 - 0.4 = 0.6

P(x|ham) = 0.2 × 0.6 = 0.12

محاسبه احتمالات پسین:
P(spam|x) ∝ 0.32 × 0.5 = 0.16

P(ham|x) ∝ 0.12 × 0.5 = 0.06

مجموع: 0.16 + 0.06 = 0.22

نرمال‌سازی: P(spam|x) = 0.16/0.22 ≈ 0.7273، P(ham|x) = 0.06/0.22 ≈ 0.2727

تصمیم نهایی:
احتمال اسپم: ≈ ۷۲.۷۳٪

احتمال غیراسپم: ≈ ۲۷.۲۷٪

تصمیم: Spam با اطمینان ≈ ۶۲.۵۰٪

