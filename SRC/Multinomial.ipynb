{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a2d78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“˜ Multinomial Naive Bayes - Educational Version (For Text/Count Data)\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def fmt(x):\n",
    "    \"\"\"Format numbers for better display\"\"\"\n",
    "    return f\"{x:.4f}\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“˜ Multinomial Naive Bayes - Educational Version (For Text/Count Data)\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2717010e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ **Section 1: Training Data - Text Documents**\n",
      "\n",
      "Vocabulary: free, win, money, meeting, project, urgent\n",
      "Vocabulary size (V) = 6\n",
      "\n",
      "Spam documents (word frequencies):\n",
      "Doc | free | win | money | meeting | project | urgent\n",
      " 1  |   3    |   2    |   4    |   0    |   0    |   1   \n",
      " 2  |   2    |   1    |   3    |   0    |   0    |   0   \n",
      " 3  |   4    |   3    |   5    |   0    |   1    |   2   \n",
      "\n",
      "Ham documents (word frequencies):\n",
      "Doc | free | win | money | meeting | project | urgent\n",
      " 1  |   0    |   0    |   1    |   3    |   2    |   0   \n",
      " 2  |   1    |   0    |   0    |   2    |   3    |   1   \n",
      " 3  |   0    |   1    |   0    |   4    |   3    |   2   \n",
      "\n",
      "ðŸ“„ **Test Document Word Counts:**\n",
      "  free    : 2\n",
      "  win     : 1\n",
      "  money   : 3\n",
      "  meeting : 0\n",
      "  project : 0\n",
      "  urgent  : 1\n"
     ]
    }
   ],
   "source": [
    "# ==================== Section 1: Training Data - Text Documents ====================\n",
    "print(\"ðŸ”¹ **Section 1: Training Data - Text Documents**\\n\")\n",
    "\n",
    "# Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ: ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ø¯Ø± Ø§Ø³Ù†Ø§Ø¯\n",
    "# Ø¯Ø§ÛŒØ±Ù‡â€ŒØ§Ù„Ù…Ø¹Ø§Ø±Ù: [\"free\", \"win\", \"money\", \"meeting\", \"project\", \"urgent\"]\n",
    "# Ù‡Ø± Ø³Ù†Ø¯ Ø¨Ù‡ ØµÙˆØ±Øª Ø¨Ø±Ø¯Ø§Ø± ÙØ±Ú©Ø§Ù†Ø³ Ú©Ù„Ù…Ø§Øª Ù†Ø´Ø§Ù† Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡\n",
    "spam_docs = [\n",
    "    [3, 2, 4, 0, 0, 1],   # Ø³Ù†Ø¯ 1: ÙØ±Ú©Ø§Ù†Ø³ Ø¨Ø§Ù„Ø§ Ø¨Ø±Ø§ÛŒ \"free\"ØŒ \"win\"ØŒ \"money\"\n",
    "    [2, 1, 3, 0, 0, 0],   # Ø³Ù†Ø¯ 2\n",
    "    [4, 3, 5, 0, 1, 2]    # Ø³Ù†Ø¯ 3\n",
    "]\n",
    "\n",
    "ham_docs = [\n",
    "    [0, 0, 1, 3, 2, 0],   # Ø³Ù†Ø¯ 1: Ú©Ù„Ù…Ø§Øª Ú©Ø§Ø±ÛŒ\n",
    "    [1, 0, 0, 2, 3, 1],   # Ø³Ù†Ø¯ 2\n",
    "    [0, 1, 0, 4, 3, 2]    # Ø³Ù†Ø¯ 3\n",
    "]\n",
    "\n",
    "vocabulary = [\"free\", \"win\", \"money\", \"meeting\", \"project\", \"urgent\"]\n",
    "V = len(vocabulary)  # Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø¯Ø§ÛŒØ±Ù‡â€ŒØ§Ù„Ù…Ø¹Ø§Ø±Ù\n",
    "\n",
    "print(\"Vocabulary: \" + \", \".join(vocabulary))\n",
    "print(f\"Vocabulary size (V) = {V}\\n\")\n",
    "\n",
    "print(\"Spam documents (word frequencies):\")\n",
    "print(\"Doc | \" + \" | \".join(vocabulary))\n",
    "for i, doc in enumerate(spam_docs):\n",
    "    print(f\" {i+1}  | \" + \" | \".join(f\"{count:^6}\" for count in doc))\n",
    "\n",
    "print(\"\\nHam documents (word frequencies):\")\n",
    "print(\"Doc | \" + \" | \".join(vocabulary))\n",
    "for i, doc in enumerate(ham_docs):\n",
    "    print(f\" {i+1}  | \" + \" | \".join(f\"{count:^6}\" for count in doc))\n",
    "\n",
    "# Ø³Ù†Ø¯ ØªØ³Øª\n",
    "test_doc = [2, 1, 3, 0, 0, 1]  # Ù…Ø´Ø§Ø¨Ù‡ Ø§Ø³Ù¾Ù…\n",
    "print(f\"\\nðŸ“„ **Test Document Word Counts:**\")\n",
    "for i, word in enumerate(vocabulary):\n",
    "    print(f\"  {word:8s}: {test_doc[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f957b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ðŸ”¹ **Section 2: Calculating Multinomial Parameters with Laplace Smoothing**\n",
      "\n",
      "Using Laplace smoothing parameter Î± = 1\n",
      "\n",
      "ðŸ“Š **For spam class:**\n",
      "  Total words in all documents: 31\n",
      "  Number of documents: 3\n",
      "\n",
      "  P('free' | spam):\n",
      "    Count of 'free' in spam: 9\n",
      "    Total words in spam: 31\n",
      "    Vocabulary size (V): 6\n",
      "    Laplace smoothing with Î± = 1:\n",
      "    Formula: (count + Î±) / (total_words + Î± Ã— V)\n",
      "    Calculation: (9 + 1) / (31 + 1 Ã— 6)\n",
      "    = 10 / 37\n",
      "    = 0.2703\n",
      "\n",
      "  P('win' | spam):\n",
      "    Count of 'win' in spam: 6\n",
      "    Total words in spam: 31\n",
      "    Vocabulary size (V): 6\n",
      "    Laplace smoothing with Î± = 1:\n",
      "    Formula: (count + Î±) / (total_words + Î± Ã— V)\n",
      "    Calculation: (6 + 1) / (31 + 1 Ã— 6)\n",
      "    = 7 / 37\n",
      "    = 0.1892\n",
      "\n",
      "  P('money' | spam):\n",
      "    Count of 'money' in spam: 12\n",
      "    Total words in spam: 31\n",
      "    Vocabulary size (V): 6\n",
      "    Laplace smoothing with Î± = 1:\n",
      "    Formula: (count + Î±) / (total_words + Î± Ã— V)\n",
      "    Calculation: (12 + 1) / (31 + 1 Ã— 6)\n",
      "    = 13 / 37\n",
      "    = 0.3514\n",
      "\n",
      "  P('meeting' | spam):\n",
      "    Count of 'meeting' in spam: 0\n",
      "    Total words in spam: 31\n",
      "    Vocabulary size (V): 6\n",
      "    Laplace smoothing with Î± = 1:\n",
      "    Formula: (count + Î±) / (total_words + Î± Ã— V)\n",
      "    Calculation: (0 + 1) / (31 + 1 Ã— 6)\n",
      "    = 1 / 37\n",
      "    = 0.0270\n",
      "\n",
      "  P('project' | spam):\n",
      "    Count of 'project' in spam: 1\n",
      "    Total words in spam: 31\n",
      "    Vocabulary size (V): 6\n",
      "    Laplace smoothing with Î± = 1:\n",
      "    Formula: (count + Î±) / (total_words + Î± Ã— V)\n",
      "    Calculation: (1 + 1) / (31 + 1 Ã— 6)\n",
      "    = 2 / 37\n",
      "    = 0.0541\n",
      "\n",
      "  P('urgent' | spam):\n",
      "    Count of 'urgent' in spam: 3\n",
      "    Total words in spam: 31\n",
      "    Vocabulary size (V): 6\n",
      "    Laplace smoothing with Î± = 1:\n",
      "    Formula: (count + Î±) / (total_words + Î± Ã— V)\n",
      "    Calculation: (3 + 1) / (31 + 1 Ã— 6)\n",
      "    = 4 / 37\n",
      "    = 0.1081\n",
      "\n",
      "----------------------------------------\n",
      "ðŸ“Š **For ham class:**\n",
      "  Total words in all documents: 23\n",
      "  Number of documents: 3\n",
      "\n",
      "  P('free' | ham):\n",
      "    Count of 'free' in ham: 1\n",
      "    Total words in ham: 23\n",
      "    Vocabulary size (V): 6\n",
      "    Laplace smoothing with Î± = 1:\n",
      "    Formula: (count + Î±) / (total_words + Î± Ã— V)\n",
      "    Calculation: (1 + 1) / (23 + 1 Ã— 6)\n",
      "    = 2 / 29\n",
      "    = 0.0690\n",
      "\n",
      "  P('win' | ham):\n",
      "    Count of 'win' in ham: 1\n",
      "    Total words in ham: 23\n",
      "    Vocabulary size (V): 6\n",
      "    Laplace smoothing with Î± = 1:\n",
      "    Formula: (count + Î±) / (total_words + Î± Ã— V)\n",
      "    Calculation: (1 + 1) / (23 + 1 Ã— 6)\n",
      "    = 2 / 29\n",
      "    = 0.0690\n",
      "\n",
      "  P('money' | ham):\n",
      "    Count of 'money' in ham: 1\n",
      "    Total words in ham: 23\n",
      "    Vocabulary size (V): 6\n",
      "    Laplace smoothing with Î± = 1:\n",
      "    Formula: (count + Î±) / (total_words + Î± Ã— V)\n",
      "    Calculation: (1 + 1) / (23 + 1 Ã— 6)\n",
      "    = 2 / 29\n",
      "    = 0.0690\n",
      "\n",
      "  P('meeting' | ham):\n",
      "    Count of 'meeting' in ham: 9\n",
      "    Total words in ham: 23\n",
      "    Vocabulary size (V): 6\n",
      "    Laplace smoothing with Î± = 1:\n",
      "    Formula: (count + Î±) / (total_words + Î± Ã— V)\n",
      "    Calculation: (9 + 1) / (23 + 1 Ã— 6)\n",
      "    = 10 / 29\n",
      "    = 0.3448\n",
      "\n",
      "  P('project' | ham):\n",
      "    Count of 'project' in ham: 8\n",
      "    Total words in ham: 23\n",
      "    Vocabulary size (V): 6\n",
      "    Laplace smoothing with Î± = 1:\n",
      "    Formula: (count + Î±) / (total_words + Î± Ã— V)\n",
      "    Calculation: (8 + 1) / (23 + 1 Ã— 6)\n",
      "    = 9 / 29\n",
      "    = 0.3103\n",
      "\n",
      "  P('urgent' | ham):\n",
      "    Count of 'urgent' in ham: 3\n",
      "    Total words in ham: 23\n",
      "    Vocabulary size (V): 6\n",
      "    Laplace smoothing with Î± = 1:\n",
      "    Formula: (count + Î±) / (total_words + Î± Ã— V)\n",
      "    Calculation: (3 + 1) / (23 + 1 Ã— 6)\n",
      "    = 4 / 29\n",
      "    = 0.1379\n"
     ]
    }
   ],
   "source": [
    "# ==================== Section 2: Calculating Multinomial Parameters with Laplace Smoothing ====================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"ðŸ”¹ **Section 2: Calculating Multinomial Parameters with Laplace Smoothing**\\n\")\n",
    "\n",
    "def calculate_multinomial_params(docs, class_name, alpha=1):\n",
    "    \"\"\"Calculate word probabilities for multinomial distribution\"\"\"\n",
    "    total_words = sum(sum(doc) for doc in docs)\n",
    "    n_docs = len(docs)\n",
    "    \n",
    "    # Ø´Ù…Ø§Ø±Ø´ Ú©Ù„ ÙˆÙ‚ÙˆØ¹ Ù‡Ø± Ú©Ù„Ù…Ù‡ Ø¯Ø± Ú©Ù„Ø§Ø³\n",
    "    word_counts = [0] * V\n",
    "    for doc in docs:\n",
    "        for i in range(V):\n",
    "            word_counts[i] += doc[i]\n",
    "    \n",
    "    print(f\"ðŸ“Š **For {class_name} class:**\")\n",
    "    print(f\"  Total words in all documents: {total_words}\")\n",
    "    print(f\"  Number of documents: {n_docs}\")\n",
    "    \n",
    "    # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø¨Ø§ Ù‡ÙˆØ´Ù…Ù†Ø¯Ø³Ø§Ø²ÛŒ Ù„Ø§Ù¾Ù„Ø§Ø³\n",
    "    probabilities = []\n",
    "    for i in range(V):\n",
    "        count = word_counts[i]\n",
    "        prob = (count + alpha) / (total_words + alpha * V)\n",
    "        probabilities.append(prob)\n",
    "        \n",
    "        print(f\"\\n  P('{vocabulary[i]}' | {class_name}):\")\n",
    "        print(f\"    Count of '{vocabulary[i]}' in {class_name}: {count}\")\n",
    "        print(f\"    Total words in {class_name}: {total_words}\")\n",
    "        print(f\"    Vocabulary size (V): {V}\")\n",
    "        print(f\"    Laplace smoothing with Î± = {alpha}:\")\n",
    "        print(f\"    Formula: (count + Î±) / (total_words + Î± Ã— V)\")\n",
    "        print(f\"    Calculation: ({count} + {alpha}) / ({total_words} + {alpha} Ã— {V})\")\n",
    "        print(f\"    = {count + alpha} / {total_words + alpha * V}\")\n",
    "        print(f\"    = {fmt(prob)}\")\n",
    "    \n",
    "    return probabilities, total_words\n",
    "\n",
    "alpha = 1  # Ù¾Ø§Ø±Ø§Ù…ØªØ± Ù‡ÙˆØ´Ù…Ù†Ø¯Ø³Ø§Ø²ÛŒ Ù„Ø§Ù¾Ù„Ø§Ø³\n",
    "print(f\"Using Laplace smoothing parameter Î± = {alpha}\\n\")\n",
    "\n",
    "p_words_spam, total_spam_words = calculate_multinomial_params(spam_docs, \"spam\", alpha)\n",
    "print(\"\\n\" + \"-\"*40)\n",
    "p_words_ham, total_ham_words = calculate_multinomial_params(ham_docs, \"ham\", alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08d4d5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ðŸ”¹ **Section 3: Calculating Document Likelihood**\n",
      "\n",
      "ðŸŽ¯ **For Spam class:**\n",
      "ðŸ“Œ **Calculating P(x | spam):**\n",
      "  Multinomial formula: P(x | class) âˆ Î _i [P(word_i | class)^{count_i}]\n",
      "  Where Î  (pi) means product over all words\n",
      "  In practice, we use log to avoid underflow:\n",
      "  log(P(x | class)) = Î£_i [count_i Ã— log(P(word_i | class))]\n",
      "\n",
      "  Word-by-word calculation:\n",
      "    'free': count=2, P=0.2703\n",
      "      Contribution: 0.2703^2 = 0.0730\n",
      "      Log contribution: 2 Ã— log(0.2703) = -2.6167\n",
      "    'win': count=1, P=0.1892\n",
      "      Contribution: 0.1892^1 = 0.1892\n",
      "      Log contribution: 1 Ã— log(0.1892) = -1.6650\n",
      "    'money': count=3, P=0.3514\n",
      "      Contribution: 0.3514^3 = 0.0434\n",
      "      Log contribution: 3 Ã— log(0.3514) = -3.1379\n",
      "    'urgent': count=1, P=0.1081\n",
      "      Contribution: 0.1081^1 = 0.1081\n",
      "      Log contribution: 1 Ã— log(0.1081) = -2.2246\n",
      "\n",
      "  Total log-likelihood = -9.6442\n",
      "  Likelihood (exp of log-likelihood) = e^-9.6442 = 0.0001\n",
      "\n",
      "ðŸŽ¯ **For Ham class:**\n",
      "ðŸ“Œ **Calculating P(x | ham):**\n",
      "  Multinomial formula: P(x | class) âˆ Î _i [P(word_i | class)^{count_i}]\n",
      "  Where Î  (pi) means product over all words\n",
      "  In practice, we use log to avoid underflow:\n",
      "  log(P(x | class)) = Î£_i [count_i Ã— log(P(word_i | class))]\n",
      "\n",
      "  Word-by-word calculation:\n",
      "    'free': count=2, P=0.0690\n",
      "      Contribution: 0.0690^2 = 0.0048\n",
      "      Log contribution: 2 Ã— log(0.0690) = -5.3483\n",
      "    'win': count=1, P=0.0690\n",
      "      Contribution: 0.0690^1 = 0.0690\n",
      "      Log contribution: 1 Ã— log(0.0690) = -2.6741\n",
      "    'money': count=3, P=0.0690\n",
      "      Contribution: 0.0690^3 = 0.0003\n",
      "      Log contribution: 3 Ã— log(0.0690) = -8.0224\n",
      "    'urgent': count=1, P=0.1379\n",
      "      Contribution: 0.1379^1 = 0.1379\n",
      "      Log contribution: 1 Ã— log(0.1379) = -1.9810\n",
      "\n",
      "  Total log-likelihood = -18.0259\n",
      "  Likelihood (exp of log-likelihood) = e^-18.0259 = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# ==================== Section 3: Calculating Document Likelihood ====================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"ðŸ”¹ **Section 3: Calculating Document Likelihood**\\n\")\n",
    "\n",
    "def multinomial_likelihood(doc, word_probs, class_name):\n",
    "    \"\"\"Calculate multinomial likelihood with log probabilities\"\"\"\n",
    "    likelihood = 0\n",
    "    log_likelihood = 0\n",
    "    \n",
    "    print(f\"ðŸ“Œ **Calculating P(x | {class_name}):**\")\n",
    "    print(\"  Multinomial formula: P(x | class) âˆ Î _i [P(word_i | class)^{count_i}]\")\n",
    "    print(\"  Where Î  (pi) means product over all words\")\n",
    "    print(\"  In practice, we use log to avoid underflow:\")\n",
    "    print(\"  log(P(x | class)) = Î£_i [count_i Ã— log(P(word_i | class))]\")\n",
    "    print()\n",
    "    \n",
    "    print(\"  Word-by-word calculation:\")\n",
    "    for i in range(V):\n",
    "        count = doc[i]\n",
    "        prob = word_probs[i]\n",
    "        if count > 0 and prob > 0:\n",
    "            term = (prob ** count)\n",
    "            log_term = count * math.log(prob)\n",
    "            likelihood_term = term\n",
    "            log_likelihood += log_term\n",
    "            \n",
    "            print(f\"    '{vocabulary[i]}': count={count}, P={fmt(prob)}\")\n",
    "            print(f\"      Contribution: {fmt(prob)}^{count} = {fmt(term)}\")\n",
    "            print(f\"      Log contribution: {count} Ã— log({fmt(prob)}) = {fmt(log_term)}\")\n",
    "    \n",
    "    likelihood = math.exp(log_likelihood)\n",
    "    print(f\"\\n  Total log-likelihood = {fmt(log_likelihood)}\")\n",
    "    print(f\"  Likelihood (exp of log-likelihood) = e^{fmt(log_likelihood)} = {fmt(likelihood)}\")\n",
    "    \n",
    "    return likelihood, log_likelihood\n",
    "\n",
    "print(\"ðŸŽ¯ **For Spam class:**\")\n",
    "p_x_spam, log_p_x_spam = multinomial_likelihood(test_doc, p_words_spam, \"spam\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ **For Ham class:**\")\n",
    "p_x_ham, log_p_x_ham = multinomial_likelihood(test_doc, p_words_ham, \"ham\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1fd045f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ðŸ”¹ **Section 4: Prior Probabilities**\n",
      "\n",
      "Prior probabilities based on document frequency:\n",
      "  Total documents: 6\n",
      "  Spam documents: 3, Ham documents: 3\n",
      "  P(spam) = 3 / 6 = 0.5000\n",
      "  P(ham) = 3 / 6 = 0.5000\n"
     ]
    }
   ],
   "source": [
    "# ==================== Section 4: Prior Probabilities ====================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"ðŸ”¹ **Section 4: Prior Probabilities**\\n\")\n",
    "\n",
    "n_spam = len(spam_docs)\n",
    "n_ham = len(ham_docs)\n",
    "n_total = n_spam + n_ham\n",
    "\n",
    "p_spam_prior = n_spam / n_total\n",
    "p_ham_prior = n_ham / n_total\n",
    "\n",
    "print(\"Prior probabilities based on document frequency:\")\n",
    "print(f\"  Total documents: {n_total}\")\n",
    "print(f\"  Spam documents: {n_spam}, Ham documents: {n_ham}\")\n",
    "print(f\"  P(spam) = {n_spam} / {n_total} = {fmt(p_spam_prior)}\")\n",
    "print(f\"  P(ham) = {n_ham} / {n_total} = {fmt(p_ham_prior)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6944672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ðŸ”¹ **Section 5: Posterior Probability Calculation**\n",
      "\n",
      "Using log probabilities for numerical stability:\n",
      "  log(P(spam | x)) âˆ log(P(x | spam)) + log(P(spam))\n",
      "  log(P(ham | x)) âˆ log(P(x | ham)) + log(P(ham))\n",
      "\n",
      "ðŸ“Š **Log Posteriors:**\n",
      "  log(P(spam | x)) = -9.6442 + log(0.5000)\n",
      "                    = -9.6442 + -0.6931\n",
      "                    = -10.3373\n",
      "\n",
      "  log(P(ham | x)) = -18.0259 + log(0.5000)\n",
      "                   = -18.0259 + -0.6931\n",
      "                   = -18.7190\n",
      "\n",
      "ðŸ“Š **Normalized Probabilities (using log-sum-exp):**\n",
      "  max(log values) = -10.3373\n",
      "  log(P(x)) = -10.3371\n",
      "  P(spam | x) = exp(-10.3373 - -10.3371)\n",
      "              = exp(-0.0002)\n",
      "              = 0.9998 = 99.9771%\n",
      "\n",
      "  P(ham | x) = exp(-18.7190 - -10.3371)\n",
      "             = exp(-8.3819)\n",
      "             = 0.0002 = 0.0229%\n"
     ]
    }
   ],
   "source": [
    "# ==================== Section 5: Posterior Probability Calculation ====================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"ðŸ”¹ **Section 5: Posterior Probability Calculation**\\n\")\n",
    "\n",
    "print(\"Using log probabilities for numerical stability:\")\n",
    "print(\"  log(P(spam | x)) âˆ log(P(x | spam)) + log(P(spam))\")\n",
    "print(\"  log(P(ham | x)) âˆ log(P(x | ham)) + log(P(ham))\")\n",
    "\n",
    "log_posterior_spam = log_p_x_spam + math.log(p_spam_prior)\n",
    "log_posterior_ham = log_p_x_ham + math.log(p_ham_prior)\n",
    "\n",
    "print(f\"\\nðŸ“Š **Log Posteriors:**\")\n",
    "print(f\"  log(P(spam | x)) = {fmt(log_p_x_spam)} + log({fmt(p_spam_prior)})\")\n",
    "print(f\"                    = {fmt(log_p_x_spam)} + {fmt(math.log(p_spam_prior))}\")\n",
    "print(f\"                    = {fmt(log_posterior_spam)}\")\n",
    "\n",
    "print(f\"\\n  log(P(ham | x)) = {fmt(log_p_x_ham)} + log({fmt(p_ham_prior)})\")\n",
    "print(f\"                   = {fmt(log_p_x_ham)} + {fmt(math.log(p_ham_prior))}\")\n",
    "print(f\"                   = {fmt(log_posterior_ham)}\")\n",
    "\n",
    "# ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª (Ø¨Ø§ ØªØ±ÙÙ†Ø¯ log-sum-exp)\n",
    "max_log = max(log_posterior_spam, log_posterior_ham)\n",
    "log_sum = max_log + math.log(math.exp(log_posterior_spam - max_log) + \n",
    "                            math.exp(log_posterior_ham - max_log))\n",
    "\n",
    "p_spam_given_x = math.exp(log_posterior_spam - log_sum)\n",
    "p_ham_given_x = math.exp(log_posterior_ham - log_sum)\n",
    "\n",
    "print(f\"\\nðŸ“Š **Normalized Probabilities (using log-sum-exp):**\")\n",
    "print(f\"  max(log values) = {fmt(max_log)}\")\n",
    "print(f\"  log(P(x)) = {fmt(log_sum)}\")\n",
    "print(f\"  P(spam | x) = exp({fmt(log_posterior_spam)} - {fmt(log_sum)})\")\n",
    "print(f\"              = exp({fmt(log_posterior_spam - log_sum)})\")\n",
    "print(f\"              = {fmt(p_spam_given_x)} = {fmt(p_spam_given_x*100)}%\")\n",
    "\n",
    "print(f\"\\n  P(ham | x) = exp({fmt(log_posterior_ham)} - {fmt(log_sum)})\")\n",
    "print(f\"             = exp({fmt(log_posterior_ham - log_sum)})\")\n",
    "print(f\"             = {fmt(p_ham_given_x)} = {fmt(p_ham_given_x*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1c270f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ðŸ”¹ **Section 6: Final Decision**\n",
      "\n",
      "ðŸŽ¯ **Classification Results:**\n",
      "  P(spam | document) = 99.9771%\n",
      "  P(ham | document)  = 0.0229%\n",
      "\n",
      "âœ… **Decision: SPAM** (higher probability of being spam)\n",
      "ðŸ“Š **Confidence: 99.9771%**\n",
      "\n",
      "ðŸ” **Word Analysis for Test Document:**\n",
      "  'free': 2 occurrences\n",
      "    P('free' | spam) = 0.2703\n",
      "    P('free' | ham)  = 0.0690\n",
      "  'win': 1 occurrences\n",
      "    P('win' | spam) = 0.1892\n",
      "    P('win' | ham)  = 0.0690\n",
      "  'money': 3 occurrences\n",
      "    P('money' | spam) = 0.3514\n",
      "    P('money' | ham)  = 0.0690\n",
      "  'urgent': 1 occurrences\n",
      "    P('urgent' | spam) = 0.1081\n",
      "    P('urgent' | ham)  = 0.1379\n",
      "\n",
      "================================================================================\n",
      "âœ… Multinomial Naive Bayes Text Classification Completed\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ==================== Section 6: Final Decision ====================\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"ðŸ”¹ **Section 6: Final Decision**\\n\")\n",
    "\n",
    "print(\"ðŸŽ¯ **Classification Results:**\")\n",
    "print(f\"  P(spam | document) = {fmt(p_spam_given_x*100)}%\")\n",
    "print(f\"  P(ham | document)  = {fmt(p_ham_given_x*100)}%\")\n",
    "\n",
    "\n",
    "if p_spam_given_x > p_ham_given_x:\n",
    "    decision = \"SPAM\"\n",
    "    confidence = (p_spam_given_x - p_ham_given_x) / p_spam_given_x\n",
    "    print(f\"\\nâœ… **Decision: {decision}** (higher probability of being spam)\")\n",
    "else:\n",
    "    decision = \"HAM\"\n",
    "    confidence = (p_ham_given_x - p_spam_given_x) / p_ham_given_x\n",
    "    print(f\"\\nâœ… **Decision: {decision}** (higher probability of being legitimate)\")\n",
    "\n",
    "print(f\"ðŸ“Š **Confidence: {fmt(confidence*100)}%**\")\n",
    "\n",
    "# Show word analysis\n",
    "print(f\"\\nðŸ” **Word Analysis for Test Document:**\")\n",
    "for i, word in enumerate(vocabulary):\n",
    "    if test_doc[i] > 0:\n",
    "        print(f\"  '{word}': {test_doc[i]} occurrences\")\n",
    "        print(f\"    P('{word}' | spam) = {fmt(p_words_spam[i])}\")\n",
    "        print(f\"    P('{word}' | ham)  = {fmt(p_words_ham[i])}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… Multinomial Naive Bayes Text Classification Completed\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
